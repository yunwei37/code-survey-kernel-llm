\section{Limitations}
\label{sec:limitations}

% While \emph{\sys} offers significant advancements in analyzing the evolution of large software systems, it has certain limitations. First, the methodology's accuracy depends heavily on the quality and completeness of input data—incomplete commit messages or fragmented discussions can lead to gaps in the structured dataset. Second, LLMs are not infallible and may misinterpret technical content or generate plausible but incorrect information (hallucinations)~\cite{ji2023survey,bubeck2023sparks}, requiring careful survey design and validation to guide responses effectively. Third, despite automation, human expertise remains essential for designing surveys, evaluating results, and ensuring contextual relevance, which can limit scalability when expert availability is constrained. These limitations highlight the need for continuous refinement of both the methodology and the underlying LLM capabilities.
While \sys offers significant advancements in understanding kernel evolution through multi-agent analysis, it has certain limitations. First, the framework's effectiveness depends on the diversity and specialization of agents—our current agents may not capture all stakeholder perspectives in the kernel community. Second, while multi-agent disagreements reveal valuable insights, they also increase computational costs and complexity compared to single-model approaches. Third, agent biases can compound when multiple agents interact, potentially amplifying certain perspectives while diminishing others. Fourth, the virtual community may not perfectly mirror real dynamics, especially for emerging technologies where historical patterns don't apply. These limitations highlight the need for continuous refinement of agent architectures and interaction protocols as we move toward the FM era.

\section{Future Work}
\label{sec:future}

% While \emph{\sys} demonstrates significant potential in organizing and analyzing unstructured software data, several areas warrant further exploration. First, to address challenges such as hallucinations and inaccuracies in LLM outputs, future work will focus on developing robust validation frameworks including benchmarking results against curated datasets and involving human experts in refining LLM outputs. Second, the current proof-of-concept showcases automation but with room for performance improvements when no human feedback is provided; future efforts will explore the use of more advanced models such as O1~\cite{o1} and the implementation of multi-agent systems to optimize performance and accuracy while ensuring compatibility with machine analysis tools. Third, while \emph{\sys} has been applied to the Linux eBPF subsystem, its methodology can be directly applied to other projects like Kubernetes, LLVM, and Apache, which will test its scalability and versatility. Finally, due to time constraints, the case study currently focuses mainly on analyzing commits and features; extending \emph{\sys} to incorporate additional data sources—such as source code, execution traces, and execution flows—will provide a more comprehensive understanding of software systems through direct structuring of code and functions into queryable data or graphs with attributes. By pursuing these enhancements, \emph{\sys} aims to become a comprehensive tool for analyzing complex software systems, benefiting both developers and researchers in software engineering.
\sys shows promise for helping legacy systems work with modern AI tools. Our initial results suggest some useful principles: multi-agent systems can help analyze old code without changing it—agents act as translators between legacy code and AI tools. By having agents represent different viewpoints (maintainer, contributor, etc.), we see patterns in how developers collaborate. When agents disagree, it often reflects real disagreements in the community, giving us data about how collaboration works. Several areas need more research. First, adding more agent types (like Performance Engineer or API Architect) could give more complete analysis. Second, better ways to combine agent opinions based on their expertise would improve results. Third, testing \sys on other old systems (mainframe COBOL, embedded code, scientific libraries) would show if our approach works beyond Linux. Fourth, having AI not just analyze but also suggest how to update legacy code could speed up modernization. Finally, studying how agents can help rather than replace human developers will be important for open-source development. Our early findings suggest that understanding legacy code needs both technical analysis and knowledge of the community that built it. By viewing the kernel as both code and a community project, \sys offers one approach to connecting old systems with new AI tools, though more work is needed to validate these ideas broadly.

% \bibliographystyle{IEEEtran}
% \bibliography{references}