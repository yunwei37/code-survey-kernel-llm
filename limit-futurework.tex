\section{Limitations}
\label{sec:limitations}

% While \emph{Code-Survey} offers significant advancements in analyzing the evolution of large software systems, it has certain limitations. First, the methodology's accuracy depends heavily on the quality and completeness of input data—incomplete commit messages or fragmented discussions can lead to gaps in the structured dataset. Second, LLMs are not infallible and may misinterpret technical content or generate plausible but incorrect information (hallucinations)~\cite{ji2023survey,bubeck2023sparks}, requiring careful survey design and validation to guide responses effectively. Third, despite automation, human expertise remains essential for designing surveys, evaluating results, and ensuring contextual relevance, which can limit scalability when expert availability is constrained. These limitations highlight the need for continuous refinement of both the methodology and the underlying LLM capabilities.
While \sys offers significant advancements in understanding kernel evolution through multi-agent analysis, it has certain limitations. First, the framework's effectiveness depends on the diversity and specialization of agents—our current agents may not capture all stakeholder perspectives in the kernel community. Second, while multi-agent disagreements reveal valuable insights, they also increase computational costs and complexity compared to single-model approaches. Third, agent biases can compound when multiple agents interact, potentially amplifying certain perspectives while diminishing others. Fourth, the virtual community may not perfectly mirror real dynamics, especially for emerging technologies where historical patterns don't apply. These limitations highlight the need for continuous refinement of agent architectures and interaction protocols as we move toward the FM era.

\section{Future Work}
\label{sec:future}

% While \emph{Code-Survey} demonstrates significant potential in organizing and analyzing unstructured software data, several areas warrant further exploration. First, to address challenges such as hallucinations and inaccuracies in LLM outputs, future work will focus on developing robust validation frameworks including benchmarking results against curated datasets and involving human experts in refining LLM outputs. Second, the current proof-of-concept showcases automation but with room for performance improvements when no human feedback is provided; future efforts will explore the use of more advanced models such as O1~\cite{o1} and the implementation of multi-agent systems to optimize performance and accuracy while ensuring compatibility with machine analysis tools. Third, while \emph{Code-Survey} has been applied to the Linux eBPF subsystem, its methodology can be directly applied to other projects like Kubernetes, LLVM, and Apache, which will test its scalability and versatility. Finally, due to time constraints, the case study currently focuses mainly on analyzing commits and features; extending \emph{Code-Survey} to incorporate additional data sources—such as source code, execution traces, and execution flows—will provide a more comprehensive understanding of software systems through direct structuring of code and functions into queryable data or graphs with attributes. By pursuing these enhancements, \emph{Code-Survey} aims to become a comprehensive tool for analyzing complex software systems, benefiting both developers and researchers in software engineering.
While \sys demonstrates significant potential in bridging legacy systems with the FM era, several areas warrant further exploration. First, expanding agent specializations to include roles like Performance Engineer, User Experience Designer, and API Architect will provide richer multi-perspective analysis. Second, developing adaptive consensus mechanisms that weight agent opinions based on context and expertise will improve insight quality. Third, while \sys has analyzed the Linux kernel, applying it to other legacy systems like mainframe COBOL, embedded firmware, and scientific computing libraries will test its versatility in legacy-AIware integration. Fourth, creating bidirectional bridges where AIware not only queries legacy systems but also suggests modernization paths based on multi-agent consensus will accelerate legacy system evolution. Finally, exploring how multi-agent architectures can facilitate human-AI collaboration in kernel development—where agents augment rather than replace developers—will shape the future of OSS in the FM era. By pursuing these enhancements, \sys aims to establish the paradigm for how multi-agent systems enable legacy software to thrive in an AI-augmented future.

% \bibliographystyle{IEEEtran}
% \bibliography{references}